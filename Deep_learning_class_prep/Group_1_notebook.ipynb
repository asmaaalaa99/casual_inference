{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Group_1_notebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvLL1mAPGXVB"
      },
      "source": [
        "## Activity 1: Implement PropensityNet "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgSu-ARcGXVD"
      },
      "source": [
        "## Hello üëãüèª\n",
        "###  ü§ñ Intructions \n",
        "The main Goal of this activity for you to understand the code implementation of PropensityNet and how it could be used to predict propensity scores. \n",
        "\n",
        " 1. Familiarise yourself with the code and make sure to understand the role of each layer in the neural network. \n",
        " 2. There are two tasks. The first task asks you some questions from the pre-class work and the network. The second one requries you to write some code. Spend 5 mintues on the first task, and then, move to the second one! Let me know if you have any questions. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udis8XzpGXVF"
      },
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT8iEiJaGXVH"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import uniform\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.layers import Dropout\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "sns.set()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJMd9-S9GXVP"
      },
      "source": [
        "## Generate data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wjmubpaGXVQ"
      },
      "source": [
        "### Create Treatment Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2epnVOmLGXVR"
      },
      "source": [
        "\"\"\"\n",
        "We generate treatment data using a random sample.\n",
        "X_1 and X_2 are two covarients. Y_t is the outcome.\n",
        "and W_t is the treatment assignment.\n",
        "\"\"\"\n",
        "\n",
        "x_1_t = uniform.rvs(loc=5, scale=1, size=1000).reshape(-1,1)\n",
        "x_2_t = uniform.rvs(loc=1, scale=1, size=1000).reshape(-1,1)\n",
        "y_T = uniform.rvs(loc=8, scale=1, size=1000).reshape(-1,1)\n",
        "w_t = np.ones(1000).reshape(-1,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH8llY3ZGXVV"
      },
      "source": [
        "#combine all of the columns to form a dataframe\n",
        "treament_df = pd.DataFrame(np.concatenate([x_1_t,x_2_t,y_T,w_t], axis=1), columns=['X_1', 'X_2', 'Y', 'W'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWaoU4NGXVe"
      },
      "source": [
        "treament_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl2C4Sy7GXVn"
      },
      "source": [
        "### Create Control Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEe2QJZUGXVp"
      },
      "source": [
        "#drop the treatment assignment column\n",
        "control_data = treament_df.copy()\n",
        "control_data = treament_df.drop(['W'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy_iTJozGXVu"
      },
      "source": [
        "#add noise to the treatment data to generate control data\n",
        "mu, sigma = 0, 0.5\n",
        "noise = np.random.normal(mu, sigma, [1000,3]) \n",
        "control_data = control_data + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra5CcUiLGXV0"
      },
      "source": [
        "control_data[\"W\"] = (np.zeros(1000).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7htGPJdcGXV5"
      },
      "source": [
        "control_data.head(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te2z46MxGXWC"
      },
      "source": [
        "#Combine both the control and the test data\n",
        "frames = [control_data, treament_df]\n",
        "full_data = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck8Sx8rJGXWF"
      },
      "source": [
        "df = full_data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5plG2TcPGXWL"
      },
      "source": [
        "## Create Traning and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcSfXvMjGXWM"
      },
      "source": [
        "X = df[df.columns[0:3]]\n",
        "Y = df[df.columns[3]]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTWeFCRPGXWP"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, input_shape=(10,3), activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Fh2oARGXWf"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwtYOBxFGXWq"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "vPnUTMt6GXWt"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEYgywPTGXWx"
      },
      "source": [
        "## Evaluate the Model on a test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Of4qCUnGXWy"
      },
      "source": [
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy of PropensityNet classifier on test set: %.2f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mrBa_N7GXW1"
      },
      "source": [
        "## Train a Logistic Regression Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_b5YuQUGXW1"
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpISJM23GXW6"
      },
      "source": [
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hDGsht7GXW_"
      },
      "source": [
        "## Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fDGbTr1GXXA"
      },
      "source": [
        "### Task 1, asnwer the following questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjugJjGoGXXA"
      },
      "source": [
        "#### 1. Print the first 10 propensity scores predicted by PropensityNet. \n",
        "#### üê£ Hint: see the output layer of PropensityNet. Can you print the probability of each class?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XtT7qEoGXXB"
      },
      "source": [
        "#### 2. What are some key challenges to train PropensityNet?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF88iztQGXXC"
      },
      "source": [
        "#### 3. Other than matching, what are some uses of propensity scores?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Og3Q1MGXXD"
      },
      "source": [
        "#### 4.In the PropensityNet application, why is it important to use a drop-out rate?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZJe5QksGXXD"
      },
      "source": [
        "#### 5. What is an activation function? Explain why ReLu is used as an activation function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzgFSbq3GXXE"
      },
      "source": [
        "#### 6. What is a loss function? Explian why Sparse Categorical Crossentropy is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvau-qjtGXXF"
      },
      "source": [
        "#### 7. What is a softmax function? Explain why it is used as an output layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LymwtgxSGXXF"
      },
      "source": [
        "#### 8. While deciding between using logistic regression or PropensityNet to calculate the propensity score, what are some of the factors that would influence your choice?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjo3wpYCGXXG"
      },
      "source": [
        "### Task 2, train PropensityNet and Logistic regression on Lalonde dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YyT-vqaGXXH"
      },
      "source": [
        "### Load the data (Make sure to fill the lines)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFEzxqfGXXI"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/asmaaalaa99/casual_inference/main/Deep_learning_class_prep/Lalaonde.csv\")\n",
        "X = df.copy()\n",
        "X = #X values\n",
        "Y = #y prediction\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NtxeljXGXXL"
      },
      "source": [
        "#### Train PropensityNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3yHY_4dGXXM"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, input_shape=(10,9), activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vptzFijhGXXU"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEUJaL9IGXXm"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAZdyp4ZGXXr"
      },
      "source": [
        "#### Test PropensityNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxgZbr3VGXXs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q_HI82KGXXv"
      },
      "source": [
        "#### Train logistic regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uaw1Z0gcGXXw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5U5xDE8GXX7"
      },
      "source": [
        "#### Test Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPFxQgUpGXX9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTWqkCPcGXYA"
      },
      "source": [
        "#### Do you notice any difference in the performace between two models? if so, which one performed better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXs4mwqDGXYB"
      },
      "source": [
        ""
      ]
    }
  ]
}