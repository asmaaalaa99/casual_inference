{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Activity 1: Implement PropensityNet "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Hello üëãüèª\n",
    "###  ü§ñ Intructions \n",
    "The main Goal of this activity for you to understand the code implementation of PropensityNet and how it could be used to predict propensity scores. \n",
    "\n",
    " 1. Familiarise yourself with the code and make sure to understand the role of each layer in the neural network. \n",
    " 2. There are two tasks. The first one requries you to write some code, and the second asks you some questions from the pre-class work and the network. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import uniform\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dropout\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "sns.set()\n"
   ]
  },
  {
   "source": [
    "## Generate data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Create Treatment Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We generate treatment data using a random sample.\n",
    "X_1 and X_2 are two covarients. Y_t is the outcome.\n",
    "and W_t is the treatment assignment.\n",
    "\"\"\"\n",
    "\n",
    "x_1_t = uniform.rvs(loc=5, scale=1, size=1000).reshape(-1,1)\n",
    "x_2_t = uniform.rvs(loc=1, scale=1, size=1000).reshape(-1,1)\n",
    "y_T = uniform.rvs(loc=8, scale=1, size=1000).reshape(-1,1)\n",
    "w_t = np.ones(1000).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all of the columns to form a dataframe\n",
    "treament_df = pd.DataFrame(np.concatenate([x_1_t,x_2_t,y_T,w_t], axis=1), columns=['X_1', 'X_2', 'Y', 'W'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        X_1       X_2         Y    W\n",
       "0  5.978022  1.172185  8.865158  1.0\n",
       "1  5.323185  1.837666  8.357500  1.0\n",
       "2  5.312050  1.381433  8.140995  1.0\n",
       "3  5.022897  1.404643  8.289280  1.0\n",
       "4  5.262753  1.652021  8.165740  1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_1</th>\n      <th>X_2</th>\n      <th>Y</th>\n      <th>W</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.978022</td>\n      <td>1.172185</td>\n      <td>8.865158</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.323185</td>\n      <td>1.837666</td>\n      <td>8.357500</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.312050</td>\n      <td>1.381433</td>\n      <td>8.140995</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.022897</td>\n      <td>1.404643</td>\n      <td>8.289280</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.262753</td>\n      <td>1.652021</td>\n      <td>8.165740</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "treament_df.head(5)"
   ]
  },
  {
   "source": [
    "### Create Control Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the treatment assignment column\n",
    "control_data = treament_df.copy()\n",
    "control_data = treament_df.drop(['W'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add noise to the treatment data to generate control data\n",
    "mu, sigma = 0, 0.5\n",
    "noise = np.random.normal(mu, sigma, [1000,3]) \n",
    "control_data = control_data + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data[\"W\"] = (np.zeros(1000).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        X_1       X_2         Y    W\n",
       "0  5.907541  0.607590  9.375177  0.0\n",
       "1  5.645699  1.385603  8.515292  0.0\n",
       "2  5.030041  1.689527  7.401516  0.0\n",
       "3  6.133297  1.744034  8.114018  0.0\n",
       "4  5.508231  1.806400  8.905058  0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X_1</th>\n      <th>X_2</th>\n      <th>Y</th>\n      <th>W</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.907541</td>\n      <td>0.607590</td>\n      <td>9.375177</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.645699</td>\n      <td>1.385603</td>\n      <td>8.515292</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.030041</td>\n      <td>1.689527</td>\n      <td>7.401516</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6.133297</td>\n      <td>1.744034</td>\n      <td>8.114018</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.508231</td>\n      <td>1.806400</td>\n      <td>8.905058</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "control_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine both the control and the test data\n",
    "frames = [control_data, treament_df]\n",
    "full_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data.copy()"
   ]
  },
  {
   "source": [
    "## Create Traning and Test sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[0:3]]\n",
    "Y = df[df.columns[3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_20 (Dense)             (None, 10, 10)            40        \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 10, 10)            0         \n_________________________________________________________________\ndense_21 (Dense)             (None, 10, 10)            110       \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 10, 10)            0         \n_________________________________________________________________\ndense_22 (Dense)             (None, 10, 10)            110       \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 10, 10)            0         \n_________________________________________________________________\ndense_23 (Dense)             (None, 10, 10)            110       \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 10, 10)            0         \n_________________________________________________________________\ndense_24 (Dense)             (None, 10, 2)             22        \n=================================================================\nTotal params: 392\nTrainable params: 392\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, input_shape=(10,3), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "## Train the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10, 3) for input Tensor(\"dense_20_input:0\", shape=(None, 10, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10, 3) for input Tensor(\"dense_20_input:0\", shape=(None, 10, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3).\n",
      "47/47 [==============================] - 0s 953us/step - loss: 1.0511 - accuracy: 0.5120\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 896us/step - loss: 0.7698 - accuracy: 0.5060\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 871us/step - loss: 0.7178 - accuracy: 0.5027\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 956us/step - loss: 0.7083 - accuracy: 0.4873\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.5193\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6976 - accuracy: 0.5127\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.5287\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6995 - accuracy: 0.5040\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 996us/step - loss: 0.7048 - accuracy: 0.4933\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 979us/step - loss: 0.7029 - accuracy: 0.4807\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 999us/step - loss: 0.6990 - accuracy: 0.4947\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 934us/step - loss: 0.6949 - accuracy: 0.5180\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 930us/step - loss: 0.6966 - accuracy: 0.4920\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5020\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 964us/step - loss: 0.6940 - accuracy: 0.5300\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 837us/step - loss: 0.6954 - accuracy: 0.5020\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 851us/step - loss: 0.6958 - accuracy: 0.5060\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 879us/step - loss: 0.6914 - accuracy: 0.5300\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 842us/step - loss: 0.6934 - accuracy: 0.5127\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6962 - accuracy: 0.4960\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5040\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.4940\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 950us/step - loss: 0.6937 - accuracy: 0.5060\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 898us/step - loss: 0.6923 - accuracy: 0.5053\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5340\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5160\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5120\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 944us/step - loss: 0.6926 - accuracy: 0.5047\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 905us/step - loss: 0.6941 - accuracy: 0.4927\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 937us/step - loss: 0.6927 - accuracy: 0.5193\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.4967\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5093\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.4967\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5200\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5080\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 922us/step - loss: 0.6909 - accuracy: 0.5293\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 934us/step - loss: 0.6911 - accuracy: 0.5067\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 877us/step - loss: 0.6923 - accuracy: 0.4967\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 890us/step - loss: 0.6904 - accuracy: 0.5187\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 858us/step - loss: 0.6941 - accuracy: 0.4967\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 925us/step - loss: 0.6933 - accuracy: 0.5193\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 921us/step - loss: 0.6927 - accuracy: 0.5073\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 884us/step - loss: 0.6898 - accuracy: 0.5540\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5207\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5187\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5260\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5260\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 884us/step - loss: 0.6938 - accuracy: 0.5167\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 956us/step - loss: 0.6923 - accuracy: 0.5213\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 883us/step - loss: 0.6886 - accuracy: 0.5373\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 967us/step - loss: 0.6915 - accuracy: 0.5033\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 909us/step - loss: 0.6946 - accuracy: 0.4980\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 939us/step - loss: 0.6922 - accuracy: 0.5120\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 880us/step - loss: 0.6895 - accuracy: 0.5367\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 907us/step - loss: 0.6898 - accuracy: 0.5287\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5073\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 897us/step - loss: 0.6904 - accuracy: 0.5273\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 964us/step - loss: 0.6925 - accuracy: 0.5127\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5087\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 978us/step - loss: 0.6874 - accuracy: 0.5540\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 917us/step - loss: 0.6931 - accuracy: 0.5040\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 970us/step - loss: 0.6921 - accuracy: 0.5260\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5113\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5420\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5447\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 957us/step - loss: 0.6902 - accuracy: 0.5187\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 969us/step - loss: 0.6887 - accuracy: 0.5420\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5233\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5247\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5100\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5400\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 937us/step - loss: 0.6836 - accuracy: 0.5387\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 911us/step - loss: 0.6878 - accuracy: 0.5420\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 984us/step - loss: 0.6856 - accuracy: 0.5420\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 986us/step - loss: 0.6881 - accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5513\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 891us/step - loss: 0.6829 - accuracy: 0.5347\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5400\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 965us/step - loss: 0.6756 - accuracy: 0.5447\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 929us/step - loss: 0.6722 - accuracy: 0.5593\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 968us/step - loss: 0.6720 - accuracy: 0.5553\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6708 - accuracy: 0.5607\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.5647\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.5713\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 999us/step - loss: 0.6550 - accuracy: 0.5660\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.5980\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6461 - accuracy: 0.6047\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6020\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.6347\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6433\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6229 - accuracy: 0.6347\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 974us/step - loss: 0.6164 - accuracy: 0.6540\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.6627\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.6037 - accuracy: 0.6567\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6760\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.6800\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.6653\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 966us/step - loss: 0.5723 - accuracy: 0.6887\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 973us/step - loss: 0.5705 - accuracy: 0.6853\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5491be210>"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n"
   ]
  },
  {
   "source": [
    "## Evaluate the Model on a test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 10, 3) for input Tensor(\"dense_20_input:0\", shape=(None, 10, 3), dtype=float32), but it was called on an input with incompatible shape (None, 3).\n",
      "16/16 [==============================] - 0s 906us/step - loss: 0.5372 - accuracy: 0.7480\n",
      "Accuracy of PropensityNet classifier on test set: 74.80\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy of PropensityNet classifier on test set: %.2f' % (accuracy*100))"
   ]
  },
  {
   "source": [
    "## Train a Logistic Regression Model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.58\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "source": [
    "## Tasks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1. Print the first 10 propensity scores predicted by PropensityNet. \n",
    "#### üê£ Hint: see the output layer of PropensityNet. Can you print the probability of each class?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 2. What are some key challenges to train PropensityNet?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 3. Other than matching, what are some uses of propensity scores?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 4.In the PropensityNet application, why is it important to use a drop-out rate?  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 5. What is an activation function? Explain why ReLu is used as an activation function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 6. What is a loss function? Explian why Sparse Categorical Crossentropy is used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 7. What is a softmax function? Explain why it is used as an output layer\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 8. While deciding between using logistic regression or PropensityNet to calculate the propensity score, what are some of the factors that would influence your choice?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('nsw_dw.dta')\n",
    "df = df.drop('data_id', axis = 1)\n",
    "df.to_csv(\"Lalaonde.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Lalaonde.csv\")\n",
    "X = df.copy()\n",
    "X = X.drop('treat', axis = 1)\n",
    "Y = df.treat\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_65 (Dense)             (None, 10, 10)            100       \n_________________________________________________________________\ndropout_52 (Dropout)         (None, 10, 10)            0         \n_________________________________________________________________\ndense_66 (Dense)             (None, 10, 10)            110       \n_________________________________________________________________\ndropout_53 (Dropout)         (None, 10, 10)            0         \n_________________________________________________________________\ndense_67 (Dense)             (None, 10, 10)            110       \n_________________________________________________________________\ndropout_54 (Dropout)         (None, 10, 10)            0         \n_________________________________________________________________\ndense_68 (Dense)             (None, 10, 10)            110       \n_________________________________________________________________\ndropout_55 (Dropout)         (None, 10, 10)            0         \n_________________________________________________________________\ndense_69 (Dense)             (None, 10, 2)             22        \n=================================================================\nTotal params: 452\nTrainable params: 452\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, input_shape=(10,9), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10, 9) for input Tensor(\"dense_65_input:0\", shape=(None, 10, 9), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 10, 9) for input Tensor(\"dense_65_input:0\", shape=(None, 10, 9), dtype=float32), but it was called on an input with incompatible shape (None, 9).\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 432.2184 - accuracy: 0.4985\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 364.1935 - accuracy: 0.5225\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 276.6648 - accuracy: 0.4745\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 279.4624 - accuracy: 0.5285\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 228.4270 - accuracy: 0.5285\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 171.2484 - accuracy: 0.5796\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 131.0571 - accuracy: 0.5345\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 137.5061 - accuracy: 0.5135\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 144.5585 - accuracy: 0.5195\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 111.8700 - accuracy: 0.5135\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 101.7555 - accuracy: 0.5015\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 87.2937 - accuracy: 0.5165\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.0179 - accuracy: 0.5135\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 59.2304 - accuracy: 0.5676\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 75.4151 - accuracy: 0.5706\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 55.2055 - accuracy: 0.5766\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.5798 - accuracy: 0.5015\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 60.3329 - accuracy: 0.5135\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 72.8462 - accuracy: 0.5736\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.7842 - accuracy: 0.5495\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 51.3329 - accuracy: 0.5375\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.5542 - accuracy: 0.5586\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 40.2780 - accuracy: 0.5375\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 64.7613 - accuracy: 0.5315\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 34.1862 - accuracy: 0.5766\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.9220 - accuracy: 0.5616\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.4700 - accuracy: 0.5375\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.5439 - accuracy: 0.6006\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.7604 - accuracy: 0.5255\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 34.6422 - accuracy: 0.5706\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.4269 - accuracy: 0.5465\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 16.2086 - accuracy: 0.5435\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.5560 - accuracy: 0.5796\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 18.7036 - accuracy: 0.5465\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.0903 - accuracy: 0.5736\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 10.0663 - accuracy: 0.5495\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 16.8837 - accuracy: 0.5375\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.8930 - accuracy: 0.6036\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.3651 - accuracy: 0.5556\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.7617 - accuracy: 0.6006\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.5480 - accuracy: 0.5826\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.0804 - accuracy: 0.5526\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.4148 - accuracy: 0.5736\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.8141 - accuracy: 0.5796\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 28.8983 - accuracy: 0.5796\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 16.1564 - accuracy: 0.5526\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 10.7480 - accuracy: 0.5676\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.9778 - accuracy: 0.5676\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 8.1952 - accuracy: 0.5736\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.1203 - accuracy: 0.5405\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 16.9795 - accuracy: 0.5916\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.6686 - accuracy: 0.5886\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.8053 - accuracy: 0.5435\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.5904 - accuracy: 0.5526\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.6819 - accuracy: 0.5736\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.9250 - accuracy: 0.5405\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.9086 - accuracy: 0.5886\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.1831 - accuracy: 0.5706\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.6231 - accuracy: 0.5526\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.6063 - accuracy: 0.5826\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.9969 - accuracy: 0.5796\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.2457 - accuracy: 0.5646\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.3758 - accuracy: 0.5976\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8475 - accuracy: 0.5646\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.4698 - accuracy: 0.6036\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 8.5927 - accuracy: 0.6096\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.5191 - accuracy: 0.5796\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 10.2157 - accuracy: 0.5946\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.1937 - accuracy: 0.5556\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.7870 - accuracy: 0.5736\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.9040 - accuracy: 0.5616\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.5844 - accuracy: 0.5886\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.3458 - accuracy: 0.5465\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.9565 - accuracy: 0.5526\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.6201 - accuracy: 0.5976\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.7317 - accuracy: 0.5766\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.6735 - accuracy: 0.5676\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.9240 - accuracy: 0.5706\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.3728 - accuracy: 0.5826\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.1979 - accuracy: 0.5766\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 10.3362 - accuracy: 0.5856\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.1339 - accuracy: 0.5826\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.2905 - accuracy: 0.5856\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3.8531 - accuracy: 0.6006\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.6340 - accuracy: 0.5916\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.4499 - accuracy: 0.5766\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.0933 - accuracy: 0.5796\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.5786 - accuracy: 0.5796\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.9689 - accuracy: 0.6036\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3804 - accuracy: 0.6096\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.6931 - accuracy: 0.5736\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4081 - accuracy: 0.5766\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.0274 - accuracy: 0.5856\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3990 - accuracy: 0.6066\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.2692 - accuracy: 0.5916\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.7723 - accuracy: 0.6036\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.4114 - accuracy: 0.6096\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.9622 - accuracy: 0.5946\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.2141 - accuracy: 0.5916\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.2528 - accuracy: 0.5916\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5554b3150>"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}