{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "training_the_model.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOVoIjvxIiwr"
      },
      "source": [
        "## Activity 1: Implement PropensityNet "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0LATS46Iiws"
      },
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NPNQrBUIiwt"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import uniform\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.layers import Dropout\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "sns.set(style=\"white\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJuIfAsIiww"
      },
      "source": [
        "## Generate data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK-Xj6OfIiwx"
      },
      "source": [
        "### Create Treatment Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B1QClspIiwx"
      },
      "source": [
        "\"\"\"\n",
        "We generate treatment data using a random sample.\n",
        "X_1 and X_2 are two covarients. Y_t is the outcome.\n",
        "and W_t is the treatment assignment.\n",
        "\"\"\"\n",
        "\n",
        "x_1_t = uniform.rvs(loc=5, scale=1, size=1000).reshape(-1,1)\n",
        "x_2_t = uniform.rvs(loc=1, scale=0, size=1000).reshape(-1,1)\n",
        "y_T = uniform.rvs(loc=8, scale=1, size=1000).reshape(-1,1)\n",
        "w_t = np.ones(1000).reshape(-1,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSn5E7dxIiw0"
      },
      "source": [
        "#combine all of the columns to form a dataframe\n",
        "treament_df = pd.DataFrame(np.concatenate([x_1_t,x_2_t,y_T,w_t], axis=1), columns=['X_1', 'X_2', 'Y', 'W'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvJVXZWmIiw2"
      },
      "source": [
        "treament_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB37SSSEIiw6"
      },
      "source": [
        "### Create Control Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ar8rf71Iiw7"
      },
      "source": [
        "#drop the treatment assignment column\n",
        "control_data = treament_df.copy()\n",
        "control_data = treament_df.drop(['W'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goMHMyQWIiw9"
      },
      "source": [
        "#add noise to the treatment data to generate control data\n",
        "mu, sigma = 0, 0.4\n",
        "noise = np.random.normal(mu, sigma, [1000,3]) \n",
        "control_data = control_data + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwoThrirIixA"
      },
      "source": [
        "control_data[\"W\"] = (np.zeros(1000).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVggJVcGIixC"
      },
      "source": [
        "control_data.head(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl6s7goJIixF"
      },
      "source": [
        "#Combine both the control and the test data\n",
        "frames = [control_data, treament_df]\n",
        "full_data = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmyL0Gw7IixH"
      },
      "source": [
        "df = full_data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDhhdOSLIixJ"
      },
      "source": [
        "## Create Traning and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To7rVXFjIixJ"
      },
      "source": [
        "X = df[df.columns[0:3]]\n",
        "Y = df[df.columns[3]]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCk1m5_MIixL"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, input_shape=(10,3), activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVgDD2wqIixO"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf1jTwN0IixQ"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "bocAujUUIixR"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlyEmqtOIixT"
      },
      "source": [
        "## Evaluate the Model on a test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6LHyScmIixU"
      },
      "source": [
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy of PropensityNet classifier on test set: %.2f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt478QadIixW"
      },
      "source": [
        "## Train a Logistic Regression Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izrX9ediIixW"
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhiKW5qjIixY"
      },
      "source": [
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFm72X_4Iixb"
      },
      "source": [
        "## Task 1: The dataset used is has an equal number of control and test datapoints. Use a sample of the test data to generate the control data. This will generate inbalance in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVHEFtEsIixb"
      },
      "source": [
        "sample_size =  #specify a number between 0 and 1000 for the number of samples.\n",
        "mu = 0\n",
        "sigma = 0.4\n",
        "control_data = treament_df.copy()\n",
        "control_data = control_data.sample(n = sample_size, replace=True, random_state=1)\n",
        "noise = np.random.normal(mu, sigma, [5,4]) \n",
        "control_data = control_data + noise\n",
        "control_data[\"W\"] = (np.zeros(sample_size).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzyF9JKLIixd"
      },
      "source": [
        "### Now, split your new data into train and test sets and re-train your models. Report the test accuracy for both models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWfzBMfTIixe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNGojFZ8Iixe"
      },
      "source": [
        "## Task 2: Mu is the mean and Sigma is the standard deviation of a Gaussian noise. Change the values of Mu and Sigma, and re-retrain your models. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRekj-dSIixe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}